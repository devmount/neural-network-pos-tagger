\input{thesis_preamble.tex} % import preamble config
% start document
\begin{document}
\pagenumbering{Roman} % große Römische Seitenummerierung
\pagestyle{empty}

% title page
\clearscrheadings\clearscrplain
\begin{center}
\includegraphics[width=0.28\textwidth]{images/logo_tu_berlin}
\vspace{8mm}

{\huge Technische Universität Berlin}\\
\vspace{2mm}
{\large Quality and Usability Lab}\\
% \vspace{1mm}
% {\large Institute of Software Engineering\\and Theoretical Computer Science}\\
\vspace{11mm}

{\Huge Part-of-Speech Tagging\\[-2mm] with Neural Networks\\[-2mm] for a Conversational Agent\\}
\vspace{20mm}
{\Huge \b{Master Thesis}}\\
{\b{Master of Science (M.Sc.)}}\\
\vspace{24mm}
\begin{tabular}{rl}
  \b{Author} & Andreas Müller\\
  \b{Major} & Computer Engineering\\
  \b{Matriculation No.} & 333471\\
   & \\
  \b{Date} & 18th May 2018 \\
  \b{1st supervisor} & Prof. Dr.-Ing. Sebastian Möller \\
  \b{2nd supervisor} & Prof. Dr. ??? \\
\end{tabular}

\end{center}
\clearpage
\pagestyle{useheadings} % normale Kopf- und Fußzeilen für den Rest

% ===================================================================================
\BlankPage

% ===================================================================================
\chapter*{Eidesstattliche Erklärung}
Hiermit versichere ich, dass ich die vorliegende Arbeit selbstständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe. Alle Ausführungen, die anderen veröffentlichten oder nicht veröffentlichten Schriften wörtlich oder sinngemäß entnommen wurden, habe ich kenntlich gemacht.

Die Arbeit hat in gleicher oder ähnlicher Fassung noch keiner anderen Prüfungsbehörde vorgelegen.
\vspace{10mm}

Berlin, den \today\\

\vspace{1cm}
\rule{.5\textwidth}{.5pt}\\
Unterschrift

% ===================================================================================
\BlankPage

% ===================================================================================
\chapter*{Abstract}
...

% ===================================================================================
\BlankPage

% ===================================================================================
\chapter*{Zusammenfassung}
...

% ===================================================================================
\BlankPage

% ===================================================================================
\tableofcontents

% ===================================================================================
\listoffigures

% ===================================================================================
\listoftables

% ===================================================================================
\chapter*{Abbreviations}\label{s.abbr}
\addcontentsline{toc}{chapter}{Abbreviations}
\markboth{Abbreviations}{Abbreviations}
\begin{acronym}[----------------]
 \acro{ACA}{\i{Artificial Conversational Agent}}
 \acro{FNN}{\i{Feed-forward Neural Network}}
 \acro{HMM}{\i{Hidden Markov Model}}
 \acro{NLP}{\i{Natural Language Processing}}
 \acro{NLTK}{\i{Natural Language Toolkit}}
 \acro{RNN}{\i{Recurrent Neural Network}}
\end{acronym}

% ===================================================================================
\chapter{Introduction}\label{c.introduction}
\pagenumbering{arabic} % now normal arabic numeration
% Turing: Artificial Intelligence
% Brown: NLP
% POS Tagging

A part-of-speech tagger is a system which automatically assigns the part of speech to words using contextual information. Potential applications for part-of-speech taggers exist in many areas including speech recognition, speech synthesis, machine translation and information retrieval in general.

% Part-of-speech tagging for natural language processing is also used in the advisory artificial conversational agent called Alex. Alex was developed to answer questions about modules and courses at the TU Berlin [2]. The system takes the written natural language requests from the user and tries to model SQL-queries out of that. To understand the natural language queries, the system uses a Hidden Markov Model (HMM) to assign tags to each word of the query (part-of-speech tagging). This HMM tagger is trained with manually created training templates that are filled with the data in the database to be queried. The few manually created sentence-templates and the slot-filling result in training data that has largely the same structure. This often leads to unwanted result when the HMM tagger is presented with a sentence, that doesn’t fit into the structure of the training templates.

\section{Scope of this Thesis}\label{c.introduction.scope}
The scope of this thesis is the development of a Neural Network based part-of-speech tagger for the advisory Artificial Conversational Agent (ACA) \Alex, the training of different language models and their evaluation with corresponding test sets.

In order to accomplish the new language models, two different Neural Network architectures are implemented: A Feed-forward Neural Network and Recurrent Neural Network. For the training of both Neural Network implementations, a corpus of tagged language data is generated with the help various input templates, which are created on the basis of logged user input data.

To evaluate the language models, a data set of known data\footnote{Data, that was already used for the training of the model} and unknown data\footnote{Data, that includes words and sentence structures, that didn't occur in the training data sets} is created. On the basis of this evaluation, both Neural Network models and the HMM are compared to each other.

In accordance to the evaluation results, the former HMM based part-of-speech tagger is then replaced by this new tagger. To guarantee a seamless integration, the new tagger is implemented as a separate module with the same program interface the old tagger already utilizes. This way no other components of the conversational agent have to be changed and the effort of the replacement is kept minimal.



\section{Related Work}\label{c.introduction.related}
...

\section{Structure of this Thesis}\label{c.introduction.structure}
As introduction, this first chapter gave a short overview about the subject of natural language processing and part-of-speech tagging in general.

The second chapter describes structure and functionality of the already existing ACA \Alex\ with the main focus on its language model and tagging interface.

Chapter \ref{c.postagging} explains the implementation of a part-of-speech tagging system with two different Neural Network approaches.

The training of the language models including the retrieval of the training data and tuning of the training parameter is described in Chapter \ref{c.training}.

Chapter \ref{c.evaluation} shows the evaluation of each language model with a generated test set and their comparison.

In conclusion the final Chapter \ref{c.conclusion} discusses and summarizes the evaluation results and gives an outlook on future work.

% ===================================================================================
\chapter{\Alex: Artificial Conversational Agent}\label{c.alex}
...

\section{System Overview}\label{c.alex.overview}
...

\section{Hidden Markov Model}\label{c.alex.hmm}
...
% It was shown before, that the Neural Network approach outperforms part-of-speech tagger that are based on statistical models (like the HMM) [3]. To address the lack of flexibility of the HMM that is currently in use, two new types of classification-models should be implemented and evaluated: Feedforward Neural Networks [1] and Recurrent Neural Networks [4].

\section{Tagging Interface}\label{c.alex.tagging}
The modular structure of \Alex\ allows for easier separation of various functions and therefore easier replaceability of certain functionalities. Besides a web crawler for current data retrieval for the database and a frontend interface module is the tagger, which is used to train a language model on the one hand and to assign tags to the words of a given input sentence on the other hand.

The implementation of this tagger utilizes a Hidden Markov Model (HMM), which is a statistical model that is particularly used for pattern recognition, speech recognition and part-of-speech tagging. \Alex\ uses an already existing implementation of the HMM Tagger from the Natural Language Toolkit (NLTK)\footnote{The Natural Language Toolkit is a collection of \i{Python} programming libraries for natural language processing, see \link{http://nltk.org}}, called \tt{HiddenMarkovModelTagger}.

To replace the existing tagger, a new tagger has to provide a class with two methods: \tt{train} and \tt{tag}. These methods are used to create the language model and apply it to unknown data.

The \tt{train} method creates a new instance of the tagger class, trains this class with the given training data and returns it. The training data itself must be a list of sentences, where a sentence is a list of tuples, containing each word of this sentence and its corresponding tag. The following exemplifies the structure of the training input data containing two sentences where each word is tagged with \i{TAG}:

\lstinputlisting[language=JSON, label={l.trainingdata}]{listings/method-train.example}

The \tt{tag} method attaches a tag to each word of an input sentence, according to the previously trained language model. The input has to be an unknown sentence as a simple list of words:

\lstinputlisting[language=JSON]{listings/method-tag-input.example}

The output is a corresponding list of tuples containing a word and its assigned tag:

\lstinputlisting[language=JSON]{listings/method-tag-output.example}


% ===================================================================================
\chapter{Part-of-Speech Tagging}\label{c.postagging}
...

\section{Feed-forward Neural Network Model}\label{c.postagging.fnn}
...

\subsection{Architecture}\label{c.postagging.fnn.architecture}
...

\subsection{Implementation}\label{c.postagging.fnn.implementation}
...

\section{Recurrent Neural Network Model}\label{c.postagging.rnn}
...

\subsection{Architecture}\label{c.postagging.rnn.architecture}
...

\subsection{Implementation}\label{c.postagging.rnn.implementation}
...

% ===================================================================================
\chapter{Training}\label{c.training}
...

\section{Data Retrieval}\label{c.training.data}
...

\section{Parameter Tuning}\label{c.training.tuning}
...

% ===================================================================================
\chapter{Evaluation and Comparison}\label{c.evaluation}
...

\section{Test Design}\label{c.evaluation.test}
...

% ===================================================================================
\chapter{Discussion and Conclusion}\label{c.conclusion}
...

\section{Summary}\label{c.conclusion.summary}
...

\section{Discussion}\label{c.conclusion.discussion}
...

\section{Future work}\label{c.conclusion.future}
...

% ===================================================================================
% \bibliographystyle{apalike}
% \bibliographystyle{plainnat}
% \bibliographystyle{abbrvnat}
% \bibliographystyle{unsrtnat}
% \bibliographystyle{alphadin}
\bibliographystyle{plain}
\bibliography{bibliography}

% ===================================================================================
\appendix
\chapter{First appendix}

\section{test}
...

\end{document}